> 能够将下面的概念串在一起进行深入阐述？
>
> 基于中断和轮询的设备访问有何区别？中断和轮询的方法论仅限于访问I/O外设吗？
>
> 如何将中断/抢占/调度结合成一个有机的整体？
>
> 上面的调度似乎仅限于CPU资源，但是能否进行拓展？
>
> （全书）强调OS的资源管理器视角。事实上这不仅限于OS，我们需要对我们所管理的资源更加了解，知道其使用方法和一些限制才能更好管理和调度它们。首先是一些硬件资源：CPU可以分成单核和多核视角，涉及到指令的执行，常见的资源分配单位是时间片，如果细化的话需要考虑到CPU内部的寄存器、各种多级缓存还有总线。内存资源要从不同的抽象级别来展开，物理内存视角可以看到页表和其他剩余物理内存，它们可以抽象出地址空间，在地址空间内部可以分成不同的数据段，具有代表意义的是数据区域的栈、堆还有静态区域。在这之外就是I/O外设和外围总线了,各种外设间有很大的不同因此这里不展开讨论。其次是一些软件（或者说逻辑上的）资源，比如共享变量、文件系统中的文件等等。不过似乎它们都可以通过RAII归结为存储系统中的共享变量。资源的不同类型、以及每类资源的复杂程度均是随着应用的需求而不断推进的，因此并没必要一开始就要求过于深入的认识。
>
> 当速度不匹配时，需要涉及到缓冲区。

目前算是对于很多事情有了一定的理解了，那么终于可以来构想一下单核同步互斥的章节需要包含一些什么内容了。

首先明确一下同步互斥的概念。同步指的是多个实体（如线程）在合作完成一项任务时在时序上存在的依赖关系。比如两个进程通过管道通信，那么在写者向管道写入数据之前，读者完全没有向下运行的必要。另外一个例子是让一个进程睡眠一段时间，事实上可以看作是计时器和进程之间的合作。这个例子值得展开的地方有很多。首先，合作的实体的类型可能完全不同。这里的话是计时器和进程。计时器涉及到的资源只有它自身，这是一个极其简单的硬件，它可以被认为是自身不断在轮询。而进程的话需要绑定到CPU上，还需要访问内存才能运行。（CPU最神奇的一点是能够进行上下文切换）睡眠最朴素的实现就是在进程中轮询直到超时。可以看到，这里只是进程单方面在访问计时器，大量的轮询浪费了CPU资源（注意进程的运行是绑定了CPU的，无论是U还是S特权级）。但实际上这些轮询本是不必要的，因为计时器本身就在不断地轮询了，那么为什么CPU还需要轮询呢（这里最大的问题可能是其他的进程完全不会推进度）？为了避免浪费过多的CPU资源，我们之前的实现是如果没有超时就先切换出去，等到切换回来的时候再检查是否超时。但是这样的话，进程向下走的时间点为超时后首次被调度到的时间点，取决于调度情况可能会产生很大的响应延迟。

但是如果引入一项额外能力：计时器可以通知CPU——也即时钟中断的话，仔细思索了一下，以往的实现：即进程加入阻塞队列，添加一个新的计时器，每次时钟中断的时候将所有超时的计时器对应的进程重新扔到就绪队列的做法延迟也不见得很低（当然我们可以直接丢到队头，但是有可能出现饥饿），毕竟我们并不是在实现一个RT系统。尽管延迟不一定优化，但是CPU开销确实能够做到最低：因为在条件满足之前睡眠进程完全不会被调度到，这能够减少大量的上下文切换开销，其中最为重要的是避免了缓存抖动现象。这也就是本章的重点——阻塞了，这个后面还会展开的。另外再小小的插入一句，由于计时器比较特殊，CPU其实还是是在做轮询，当然大部分轮询都是为了进行时间片划分，仅有少部分中断与计时器相关（理想情况下计时器应该可以设置多个超时时间，但是在RV上我们只能设置一个，当然如果实现精细的话还是能够大幅提升计时精确度的），它只是轮询频率大幅降低，相对CPU总资源而言占比极少而已。

接下来便是互斥。当多个实体进行合作的时候，其中或多或少会涉及到一些共享资源。在对资源进行访问的时候，需要保证访问操作在时间上两两分隔开来，也即所谓的串行化。其中最典型的便是线程间的合作需要共享内存。我们不妨回顾一下Go语言的核心哲学：“不要通过共享内存来通信，而是通过通信来共享内存”。其思路大概是线程之间可以接受或发送一些token，token中保存了共享变量的引用，拿到token的线程便视为对于该共享变量有了独占的访问权限，在访问之后，线程可以将该token交还给资源管理器或者直接传给其他线程。但是这有一个问题：通信其实也是一种同步手段，那么它又是如何实现的呢？其实不难发现它也需要基于底层的互斥原语来完成同步。不过它的意义是？也许比锁更加轻量级？这个就不太清楚了。

---

同步互斥（单核）的下一步规划，由于目前手头没有电脑就先从这个备忘录开始吧。之前我们已经分析过同步和互斥的概念，那接下来就是如何把这些概念通过实际的例子展现出来。

大概可以分成这样两个方面：单核上有哪些可用的同步互斥原语（这里不做区分，因为很多原语兼具这两个功能），以及利用它们可以解决哪些问题。

ucore里面提到的同步互斥的底层支撑是定时器、关中断和阻塞队列。其中中断+阻塞是一种经典的同步原语，它需要内核调度器的支持以及CPU对于中断的支持。相比朴素轮询和yield加轮询，它可以显著提高CPU利用率。这里的中断也许可以泛化为软件或硬件意义上的一种信号，软件信号如写者在管道中写入数据之后需要通过内核间接唤醒读者、又比如内核中的kill信号等；而硬件信号就是中断，这个就是负责发送信号的是硬件，如时钟中断（来自定时器）和外部中断（来自各种IO外设），也许我们归结为信号加中断会更好。再总结一下它的总体流程：一个任务发现自己需要某些条件满足才能继续向下执行，于是内核将其阻塞（阻塞队列可以看做阻塞机制的具体算法实现），随后被等待者发送软件或硬件信号被内核捕获到，从而唤醒之前等待的任务。

那可以和我们之前的纯轮询以及轮询加yield做一个对比。目前仅考虑单核。单核情况下，纯轮询会浪费大量时钟周期，而且如果等待的是软件信号可能出现由于已经占用了处理器而永远接收不到信号的情况。如果有yield的话，这会带来大量上下文切换开销，且如果维持原有调度算法的话，信号处理的延迟不可预测。

实际上，即便引入中断加阻塞，也不仅仅是加上一个阻塞队列即可。我们确实还需要基于优先级的抢占机制。

---

接下来需要考虑的是我们需要对内核做出哪些变更，大概可以分成两个不同层级：同步原语和应用。

根据下面对于中断的分析可知，最基础的原语应该是spinlock，分为两种类型——关中断和不需要关中断的。这个是在多核上，在单核上则退化为我们实现的UPSafeCell，同样分为关中断和不需要关中断的，或者是提供两种不同用法。（有的时候似乎麻烦在，仅保证单个数据结构互斥不见得总体上有效）当然，在单核上，不关中断的版本仅用于绕过Rust的检查，关中断才会有一点实际意义。宗旨是：在单核上不要提锁，因为一切都可以做到完全无冲突的串行（最多是要求关中断）。因此，锁没有存在的必要。

一般来说，后面应该要涉及到信号量、互斥锁、条件变量这些东西。但是在单核上真的有意义吗？我总觉得它们也会同样进行退化才是。我想应该需要进行一下区分，信号量、互斥锁和条件变量这些应当是基于底层的两个版本的spinlock实现的，它们相对比较上层，而且允许在持有它们的情况下进入中断。但是，在持有和释放它们的过程中，可能会存在关中断的临界区，毕竟它们的底层可能需要关中断spinlock的支持。

信号量、互斥锁、条件变量它们自身就都比较简单了。它们的关键在于要提供获取和释放这一对操作。信号量semaphore（Linux里面提供的sem系列syscall看上去是用于pthread之间的同步，由于mmap机制的缺陷不太可能将其用于进程间通信，而且在单核上本来就没意义），要求是最多同时只能有有限个任务位于临界区。它的结构体内理应有一个整数的可用容量以及当前的阻塞队列。这个结构需要一个关中断spinlock进行保护，其实这里严格来说并不需要关中断，而只是禁止调度。也许我们可以保留一个全局的调度使能标志，如果从S态进入时钟中断的话，可以检查该标志，如果被禁止的话则原路返回。事实上不仅限于这一个数据结构，原来使用UPSafeCell可以搞定的内容，一旦在内核态打开了中断（除非目前已经处于中断中）都需要禁止调度，因为绝不能在数据结构不一致的状态下进行任务切换。因此，这里可以有两种做法：第一种就是直接使用关中断的spinlock，而第二种则是打上禁止调度的标志在时钟中断的时候检查一下。看上去的话，确实是第一种一刀切的做法比较简单。

> 这里其实又有两种情况：在执行内核线程的时候和进行系统调用的时候打开中断的效果也许有些不同。

其次，比较基础的是它比较特殊的一点是要允许在临界区中打开中断并进行可能的上下文切换。信号量提供p/v操作，它们都可以利用底层的信号+阻塞机制来实现。在操作的时候，都需要read-update信号量的容量这个共享变量，并看情况阻塞自身或是给其他任务发唤醒信号。设想一下，

> 这里需要插楼仔细分析一下时钟中断。由于它涉及到CPU关键的时间片调度，它不太能和外部/软件中断一样简单看成一个来自I/O外设或软件任务的完成信号。时钟中断可以看作是计时器给CPU发的一种信号，用于通知OS来进行任务切换。与其他中断不同的是，它更偏向同步，因为下一次的触发时间是由CPU自己设置的。另外就是，它属于一种局部中断。
>
> 回顾一下xv6对于中断的处理方式。我觉得目前rcore和xv6的思路是一样的，即用户调用内核，从而内核栈上的数据不能正常回收。相比而言，内核调用用户就会更加合理。后面我们可以看一下luojia的生成器那篇文章。
>
> xv6貌似不存在内核态的常驻任务。
>
> xv6对于锁和中断的交互是比较保守的：它会确保在任何spinlock的临界区中关闭中断从而避免由中断带来的可能的并发冲突。事实上，确实很难去审计内核中的哪些数据结构会被中断服务例程和其他执行流所用到从而带来冲突。因为，可能有多种不同数据结构，它们之间的顺序如何？一般在多核环境下，我们只需要按照某种特定的全局顺序来获取锁即可有效避免死锁，那么这里可否使用相同的思路来代替？但是需要注意到中断和多核的情况不太一样，如果进入中断的时候持有了锁（无论任何类型），而在中断服务例程中需要访问相同的数据结构，这势必带来死锁。（注意我们不能在这个时候将所有权暂时转移到中断服务例程，因为进入中断的时候可能正处于临界区之中，这里再去修改该数据结构会带来不一致性）。在多核环境下就不是如此，如果另一个核上的一个线程想要获取锁的话，无非就是多等待一会即可。如果不像xv6这样保守的话，也许需要将使用不同的两种临界区来保护不同的数据结构，对于中断中可能会用到的数据结构，则必须在获取到锁之后关中断。这样即可保证在进入中断的时候，对于可能会用到的任何数据结构，目前均不持有它们的锁。但是有这样一种情况，目前其他核上的线程正持有着锁，那么中断服务例程就需要等待了。
>
> 我们可以考虑一些不同的中断中可能会使用到哪些数据结构：
>
> * 时钟中断：主要是进行调度或者和检查计时器是否超时
> * 外部中断：仅跟I/O外设有关，比如virtio的VirtQueue就是相关的数据结构，如果打开外部中断的话完全有可能出现在进行文件系统操作的时候出现了virtio-blk中断的情况，需要避免并发冲突
> * 软件中断：这个相对来说似乎比较简单
>
> 另外，在信号+阻塞编程模型下，它们都有可能唤醒一些任务或进程，不过这也算在调度模块之内吧。
>
> 我们可以先模仿xv6的保守做法，随后尝试一下进行分解，如果发现隐藏的冲突太多的话就放弃。话说这可能需要形式化验证的手段才能完美解决吧。
>
> ---
>
> 好像需要引入一个基本常识：也就是不同特权级之间不会看到同一个锁。这应该是显然的。
>
> ---
>
> 接下来必须分析一下在何种状态下打开中断。在RV架构下，一旦通过trap进入到S特权级，sstatus.sie被硬件关闭，从而屏蔽掉S态所有中断（注意U态所有中断被自动屏蔽，而M态所有中断不能被屏蔽且会抢占），这等于是整个内核态均关闭中断。目前期望的一种做法是仅在trap类型为系统调用的时候打开S态中断开关，而trap类型为中断的话不打开中断开关，这样的话便不会产生中断嵌套。为了尽可能不丢失中断，中断处理的过程以及关中断spinlock的临界区需要尽可能短。
>
> 如果在内核态执行的时候触发S态中断，此时我们需要新增一套trap上下文保存与恢复代码，将trap上下文原地保存在内核栈上，如果是时钟中断的话，似乎也可以自然的进行任务切换。好像也就不用一些其他的东西了。目前完全没有必要进行中断嵌套了。
>
> ---
>
> 那么xv6是如何处理的呢？与我所想的差不多，时钟中断仅在hart0上处理，且仅在U态trap到S态类型为syscall的时候会重新打开中断。如果是从S Trap到S，仅有系统调用嵌套S态中断一种可能，此时如果sstatus.sie=1会panic。

---

接下来，需要研究进行的是内核态同步互斥（基于内核线程）还是用户态同步互斥（基于进程），它们分别需要调用怎样的接口或者是哪些系统调用。

