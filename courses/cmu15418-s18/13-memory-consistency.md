之前提到过，当多核内存架构满足如下性质时，我们会认为它是正确的：即读到的值总是任意线程最后一次写入的值。在这里我们并没有对写入所带来的影响作任何约束，因为它们在读取的时候便能得到充分体现。但是究竟如何定义“最后一次”呢？在UP情况下仅需按照程序顺序即可（微架构实现的多发射和乱序执行对它是透明的）。在多核环境下，我们可能试图以物理时间为指标对内存操作进行排序，但实际上基于真实硬件是无法做到这一点的。比如，当两个核之间的最低通信延迟为10个cycle的时候，一个核不可能知道另一个核在2个cycle之前做了什么事情。

> 为何能从通信延迟的角度来说明以物理时间为标准不可能成立呢？这里的语境应当是以issue操作的物理时间作为判定标准。考虑写后读的场景，尽管写操作issue的物理时间靠前，但是另一个核不可能读到这次写入的值，因为两次操作中间的间隔不足以完成一次完整的通信。但是这种解释也有点问题。如果以操作完成的物理时间作为基准又会如何？
>
> 或者，假使两个操作恰巧发生在同一物理时间，终归是需要某个硬件单元确定其“最终顺序”（也许在顺序一致性模型中才需要）。从这个角度来反驳物理时间论也可。

这里举了一个例子。并行执行3个线程，前两个线程分别按照从小到大的顺序将变量X改为1~N的奇数和偶数，第三个线程则对变量X进行若干次读取。 那么不难想象，第三个线程看到的X值的序列必然是奇偶两个有序子序列归并起来的结果。	

可以尝试从这个例子中提炼出一些基本性质。首先，每个线程的**写入**顺序必须与该线程的程序顺序一致。有趣的是，这里为何只强调写入？又如何来定义写入顺序？在多发射和乱序执行的条件下，这甚至就和前面的“最后一次写入”一样难以定义。看来必须花时间去回顾一下ILP的相关知识了，不然可能都没有一些基本的概念。另外，全部写入的排序需要与一种合法的线程换入换出的顺序一致（实际上只是理论上的，硬件无需严格满足）。

事实上从单变量的角度就是如此。设想一下，处理器当然不会对向同一个内存位置的写入进行重排。多核虽然并行写入，但是一定会被总线进行串行从而达成某种意义上的归并。需要注意的是，这里读取和写入之间的差异尤为关键，后面再仔细讨论。

缓存一致性协议主要是针对读取和写入同一个缓存行的正确性。事实上我们也很容易看出，在缓存一致性协议中，不同的缓存行之间不会产生任何影响。如果简单总结的话，缓存一致性协议仅仅是搭建了一条数据通路使得一个核写入的数据终将被另一个核看到。但是另一个核何时看到这个数据在缓存一致性协议中是没办法被保证的。相比而言，内存一致性模型（memory consistency model）又称内存顺序（memory order）可以涉及多个不同的缓存行的读写。

一致性必须同时对consistency和coherence进行约束，这使得它非常复杂。如果分析它的原因的话可能有以下几点：首先是为了得到可以接受的性能，缓存（特别是write-back策略的缓存）必须存在，这就需要复杂的同步机制。其次，程序员希望每条指令都能够被原子地且保持程序顺序执行，但实际上处理器会对指令进行重排来提高性能。在单核情况下指令虽然乱序执行但顺序提交，使得程序员的期待似乎是成立的，然而在物理上并非如此。一旦引入其他核的影响，一切就会更加混乱了。

现代处理器可能包含的一些机制有：在一条访存指令尚未完成之时就开始发射并执行另一条访存指令，使得它们的执行在时间上存在交集，同时也使得**实际访存的顺序的顺序并不遵循程序顺序**（对于分支指令同样如此）。当然，数据依赖不会被破坏。另外，通过write buffer可以降低写入的延迟（但相对而言读取会变得更为复杂），在单核上容易实现，在多核上则不易正确实现。

后面给了一个形象的比喻：在一个线程上执行的所有指令就像一个手拧气球里面的气体分子，它们会在气球里面自由移动。但是一旦某个线程观察到另一个线程上的内存操作（可能完全杂乱无章）之后，我们就需要找到气球内对应的气体分子并通过拧气球的方式将其固定起来，这也是我们能做的唯一一件事。

> 目前为止这个比喻还有些迷惑。

单核情况下的内存模型很简单。至少在程序员看来，它就是指令原子执行、保持程序顺序的。在这里我们不去过多探讨微架构实现的细节了（值得一提的是可能存在write buffer。）但是在多核情况下，对于不同内存位置的访问顺序就变得很重要了。比如A和ready初始值都是0，线程P1修改A为1然后修改ready为1；线程P2循环等待ready变成1而后读取修改后的A。这样两个线程就完成了一次简单的通信。可是问题在于，如果是多个cache controller通过总线通信的话，很有可能出现这种情况：P2看到ready变为1，但是此时读取A却还是0。本质上来讲，是ready被修改的消息相比A更早被P2接受到，这是完全有可能的。也就是说，**顺序发射的内存操作可能被另一个线程以不同的顺序观察到**。（这里观察的方式主要是读取）其后果还是很严重的，至少在这个例子中我们可以看到同步失败了。若是考虑到cache的存在，一切还会变的更加复杂。

1979年，Lamport提出了顺序一致性模型。也即每个核都按照程序顺序进行内存访问，同时全部的内存访问均是有序的（不知道这里理解是否正确，原文是sequential order）。因此，程序员假定的访存顺序是可以被保证的。在顺序一致性下考虑刚才P1/P2的问题，P2看到的ready/A的结果为0,0/1,1/0,1均有可能，只有1,0是不可能的。因为P2观察到ready为1，说明P1上已经修改了ready，由P1上的程序顺序可以知道A也已经被修改了，于是P2理应观察到A也被修改了。但是真的如此吗？事实上在真实硬件上是完全有可能出现这种情况的。后面还给出了另一个基于软件同步的例子。

于是，应当如何正确实现顺序一致性模型呢？首先必须正确实现缓存一致性协议，使得对同一个内存位置的所有写入都能被所有的核以相同的顺序观察到。其次，对于每个核不要进行多发射和乱序执行，保证上一个内存操作完成之后再开始下一个。那么，如何判断一个内存操作是否完成呢？对于读取而言，当然是读到一个值就完成了。而对于写入而言，这需要写入的新值能够被所有核看到（原文用的是visible）。这里的“看到”是指能够看到而非已经看到，也就是说其他核的cache不一定需要发生变化。这里更多的是指写入的新值被提交到一个理论上的串行顺序（HSO，hypothetical serializable order）中，我们通过串行顺序来规定最后一次写入的是哪个值（注意，只有顺序一致性模型才是这样的）。简单起见，我们假设这个写入过程是原子的。

我们对顺序一致性模型进行小结。它最明显的特点就是每个核的内存操作（无论读写）均是串行且遵循程序顺序的。然而，它很大程度上限制了硬件和编译器对指令执行的优化，从而无法得到较高的性能。从硬件执行层面上讲，每个core同一时间仅会发射一条内存操作指令并且**插入气泡等待其执行完毕**。这使得即使在存在cache的情况下，处理器的利用率都仅有17%~42%。

顺序一致性模型有些过于严格了。因为所有的四种情况R->R,R->W,W->R,W->R均不允许交换，需要保持程序顺序。如果允许W->R交换的话，这种一致性模型被称为TSO（Total Store Ordering），类似于Intel采用的内存模型；而同时允许W->R,W->W交换的话，这种一致性模型被称为PSO（Partial Store Ordering）。由于write buffer的存在，采用TSO可以大大降低写入操作的延迟，但用来同步的时间可能有少量增加。

但是程序在弱一致性模型下能否正常运转呢？事实上是可以的。大多数程序并不需要SC便能保证正确性。[p27](http://www.cs.cmu.edu/afs/cs/academic/class/15418-s18/www/lectures/13_consistency.pdf)就给出了一个直观的例子。但是我们如何知道在何种约束下程序才能正确运行呢？当同时可能有多个线程读写同一块内存的时候，除了每个线程自身的程序顺序之外，为了让程序正常运行还需要...

