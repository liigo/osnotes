> 能够将下面的概念串在一起进行深入阐述？
>
> 基于中断和轮询的设备访问有何区别？中断和轮询的方法论仅限于访问I/O外设吗？
>
> 如何将中断/抢占/调度结合成一个有机的整体？
>
> 上面的调度似乎仅限于CPU资源，但是能否进行拓展？
>
> （全书）强调OS的资源管理器视角。事实上这不仅限于OS，我们需要对我们所管理的资源更加了解，知道其使用方法和一些限制才能更好管理和调度它们。首先是一些硬件资源：CPU可以分成单核和多核视角，涉及到指令的执行，常见的资源分配单位是时间片，如果细化的话需要考虑到CPU内部的寄存器、各种多级缓存还有总线。内存资源要从不同的抽象级别来展开，物理内存视角可以看到页表和其他剩余物理内存，它们可以抽象出地址空间，在地址空间内部可以分成不同的数据段，具有代表意义的是数据区域的栈、堆还有静态区域。在这之外就是I/O外设和外围总线了,各种外设间有很大的不同因此这里不展开讨论。其次是一些软件（或者说逻辑上的）资源，比如共享变量、文件系统中的文件等等。不过似乎它们都可以通过RAII归结为存储系统中的共享变量。资源的不同类型、以及每类资源的复杂程度均是随着应用的需求而不断推进的，因此并没必要一开始就要求过于深入的认识。
>
> 当速度不匹配时，需要涉及到缓冲区。

目前算是对于很多事情有了一定的理解了，那么终于可以来构想一下单核同步互斥的章节需要包含一些什么内容了。

首先明确一下同步互斥的概念。同步指的是多个实体（如线程）在合作完成一项任务时在时序上存在的依赖关系。比如两个进程通过管道通信，那么在写者向管道写入数据之前，读者完全没有向下运行的必要。另外一个例子是让一个进程睡眠一段时间，事实上可以看作是计时器和进程之间的合作。这个例子值得展开的地方有很多。首先，合作的实体的类型可能完全不同。这里的话是计时器和进程。计时器涉及到的资源只有它自身，这是一个极其简单的硬件，它可以被认为是自身不断在轮询。而进程的话需要绑定到CPU上，还需要访问内存才能运行。（CPU最神奇的一点是能够进行上下文切换）睡眠最朴素的实现就是在进程中轮询直到超时。可以看到，这里只是进程单方面在访问计时器，大量的轮询浪费了CPU资源（注意进程的运行是绑定了CPU的，无论是U还是S特权级）。但实际上这些轮询本是不必要的，因为计时器本身就在不断地轮询了，那么为什么CPU还需要轮询呢（这里最大的问题可能是其他的进程完全不会推进度）？为了避免浪费过多的CPU资源，我们之前的实现是如果没有超时就先切换出去，等到切换回来的时候再检查是否超时。但是这样的话，进程向下走的时间点为超时后首次被调度到的时间点，取决于调度情况可能会产生很大的响应延迟。

但是如果引入一项额外能力：计时器可以通知CPU——也即时钟中断的话，仔细思索了一下，以往的实现：即进程加入阻塞队列，添加一个新的计时器，每次时钟中断的时候将所有超时的计时器对应的进程重新扔到就绪队列的做法延迟也不见得很低（当然我们可以直接丢到队头，但是有可能出现饥饿），毕竟我们并不是在实现一个RT系统。尽管延迟不一定优化，但是CPU开销确实能够做到最低：因为在条件满足之前睡眠进程完全不会被调度到，这能够减少大量的上下文切换开销，其中最为重要的是避免了缓存抖动现象。这也就是本章的重点——阻塞了，这个后面还会展开的。另外再小小的插入一句，由于计时器比较特殊，CPU其实还是是在做轮询，当然大部分轮询都是为了进行时间片划分，仅有少部分中断与计时器相关（理想情况下计时器应该可以设置多个超时时间，但是在RV上我们只能设置一个，当然如果实现精细的话还是能够大幅提升计时精确度的），它只是轮询频率大幅降低，相对CPU总资源而言占比极少而已。

接下来便是互斥。当多个实体进行合作的时候，其中或多或少会涉及到一些共享资源。在对资源进行访问的时候，需要保证访问操作在时间上两两分隔开来，也即所谓的串行化。其中最典型的便是线程间的合作需要共享内存。我们不妨回顾一下Go语言的核心哲学：“不要通过共享内存来通信，而是通过通信来共享内存”。其思路大概是线程之间可以接受或发送一些token，token中保存了共享变量的引用，拿到token的线程便视为对于该共享变量有了独占的访问权限，在访问之后，线程可以将该token交还给资源管理器或者直接传给其他线程。但是这有一个问题：通信其实也是一种同步手段，那么它又是如何实现的呢？其实不难发现它也需要基于底层的互斥原语来完成同步。不过它的意义是？也许比锁更加轻量级？这个就不太清楚了。

---

同步互斥（单核）的下一步规划，由于目前手头没有电脑就先从这个备忘录开始吧。之前我们已经分析过同步和互斥的概念，那接下来就是如何把这些概念通过实际的例子展现出来。

大概可以分成这样两个方面：单核上有哪些可用的同步互斥原语（这里不做区分，因为很多原语兼具这两个功能），以及利用它们可以解决哪些问题。

ucore里面提到的同步互斥的底层支撑是定时器、关中断和阻塞队列。其中中断+阻塞是一种经典的同步原语，它需要内核调度器的支持以及CPU对于中断的支持。相比朴素轮询和yield加轮询，它可以显著提高CPU利用率。这里的中断也许可以泛化为软件或硬件意义上的一种信号，软件信号如写者在管道中写入数据之后需要通过内核间接唤醒读者、又比如内核中的kill信号等；而硬件信号就是中断，这个就是负责发送信号的是硬件，如时钟中断（来自定时器）和外部中断（来自各种IO外设），也许我们归结为信号加中断会更好。再总结一下它的总体流程：一个任务发现自己需要某些条件满足才能继续向下执行，于是内核将其阻塞（阻塞队列可以看做阻塞机制的具体算法实现），随后被等待者发送软件或硬件信号被内核捕获到，从而唤醒之前等待的任务。

那可以和我们之前的纯轮询以及轮询加yield做一个对比。目前仅考虑单核。单核情况下，纯轮询会浪费大量时钟周期，而且如果等待的是软件信号可能出现由于已经占用了处理器而永远接收不到信号的情况。如果有yield的话，这会带来大量上下文切换开销，且如果维持原有调度算法的话，信号处理的延迟不可预测。

实际上，即便引入中断加阻塞，也不仅仅是加上一个阻塞队列即可。我们确实还需要基于优先级的抢占机制。

---

接下来需要考虑的是我们需要对内核做出哪些变更，大概可以分成两个不同层级：同步原语和应用。

根据下面对于中断的分析可知，最基础的原语应该是spinlock，分为两种类型——关中断和不需要关中断的。这个是在多核上，在单核上则退化为我们实现的UPSafeCell，同样分为关中断和不需要关中断的，或者是提供两种不同用法。（有的时候似乎麻烦在，仅保证单个数据结构互斥不见得总体上有效）当然，在单核上，不关中断的版本仅用于绕过Rust的检查，关中断才会有一点实际意义。宗旨是：在单核上不要提锁，因为一切都可以做到完全无冲突的串行（最多是要求关中断）。因此，锁没有存在的必要。

一般来说，后面应该要涉及到信号量、互斥锁、条件变量这些东西。但是在单核上真的有意义吗？我总觉得它们也会同样进行退化才是。我想应该需要进行一下区分，信号量、互斥锁和条件变量这些应当是基于底层的两个版本的spinlock实现的，它们相对比较上层，而且允许在持有它们的情况下进入中断。但是，在持有和释放它们的过程中，可能会存在关中断的临界区，毕竟它们的底层可能需要关中断spinlock的支持。

信号量、互斥锁、条件变量它们自身就都比较简单了。它们的关键在于要提供获取和释放这一对操作。信号量semaphore（Linux里面提供的sem系列syscall看上去是用于pthread之间的同步，由于mmap机制的缺陷不太可能将其用于进程间通信，而且在单核上本来就没意义），要求是最多同时只能有有限个任务位于临界区。它的结构体内理应有一个整数的可用容量以及当前的阻塞队列。这个结构需要一个关中断spinlock进行保护，其实这里严格来说并不需要关中断，而只是禁止调度。也许我们可以保留一个全局的调度使能标志，如果从S态进入时钟中断的话，可以检查该标志，如果被禁止的话则原路返回。事实上不仅限于这一个数据结构，原来使用UPSafeCell可以搞定的内容，一旦在内核态打开了中断（除非目前已经处于中断中）都需要禁止调度，因为绝不能在数据结构不一致的状态下进行任务切换。因此，这里可以有两种做法：第一种就是直接使用关中断的spinlock，而第二种则是打上禁止调度的标志在时钟中断的时候检查一下。看上去的话，确实是第一种一刀切的做法比较简单。

> 这里其实又有两种情况：在执行内核线程的时候和进行系统调用的时候打开中断的效果也许有些不同。

其次，比较基础的是它比较特殊的一点是要允许在临界区中打开中断并进行可能的上下文切换。信号量提供p/v操作，它们都可以利用底层的信号+阻塞机制来实现。在操作的时候，都需要read-update信号量的容量这个共享变量，并看情况阻塞自身或是给其他任务发唤醒信号。设想一下，

> 这里需要插楼仔细分析一下时钟中断。由于它涉及到CPU关键的时间片调度，它不太能和外部/软件中断一样简单看成一个来自I/O外设或软件任务的完成信号。时钟中断可以看作是计时器给CPU发的一种信号，用于通知OS来进行任务切换。与其他中断不同的是，它更偏向同步，因为下一次的触发时间是由CPU自己设置的。另外就是，它属于一种局部中断。
>
> 回顾一下xv6对于中断的处理方式。我觉得目前rcore和xv6的思路是一样的，即用户调用内核，从而内核栈上的数据不能正常回收。相比而言，内核调用用户就会更加合理。后面我们可以看一下luojia的生成器那篇文章。
>
> xv6貌似不存在内核态的常驻任务。
>
> xv6对于锁和中断的交互是比较保守的：它会确保在任何spinlock的临界区中关闭中断从而避免由中断带来的可能的并发冲突。事实上，确实很难去审计内核中的哪些数据结构会被中断服务例程和其他执行流所用到从而带来冲突。因为，可能有多种不同数据结构，它们之间的顺序如何？一般在多核环境下，我们只需要按照某种特定的全局顺序来获取锁即可有效避免死锁，那么这里可否使用相同的思路来代替？但是需要注意到中断和多核的情况不太一样，如果进入中断的时候持有了锁（无论任何类型），而在中断服务例程中需要访问相同的数据结构，这势必带来死锁。（注意我们不能在这个时候将所有权暂时转移到中断服务例程，因为进入中断的时候可能正处于临界区之中，这里再去修改该数据结构会带来不一致性）。在多核环境下就不是如此，如果另一个核上的一个线程想要获取锁的话，无非就是多等待一会即可。如果不像xv6这样保守的话，也许需要将使用不同的两种临界区来保护不同的数据结构，对于中断中可能会用到的数据结构，则必须在获取到锁之后关中断。这样即可保证在进入中断的时候，对于可能会用到的任何数据结构，目前均不持有它们的锁。但是有这样一种情况，目前其他核上的线程正持有着锁，那么中断服务例程就需要等待了。
>
> 我们可以考虑一些不同的中断中可能会使用到哪些数据结构：
>
> * 时钟中断：主要是进行调度或者和检查计时器是否超时
> * 外部中断：仅跟I/O外设有关，比如virtio的VirtQueue就是相关的数据结构，如果打开外部中断的话完全有可能出现在进行文件系统操作的时候出现了virtio-blk中断的情况，需要避免并发冲突
> * 软件中断：这个相对来说似乎比较简单
>
> 另外，在信号+阻塞编程模型下，它们都有可能唤醒一些任务或进程，不过这也算在调度模块之内吧。
>
> 我们可以先模仿xv6的保守做法，随后尝试一下进行分解，如果发现隐藏的冲突太多的话就放弃。话说这可能需要形式化验证的手段才能完美解决吧。
>
> ---
>
> 好像需要引入一个基本常识：也就是不同特权级之间不会看到同一个锁。这应该是显然的。
>
> ---
>
> 接下来必须分析一下在何种状态下打开中断。在RV架构下，一旦通过trap进入到S特权级，sstatus.sie被硬件关闭，从而屏蔽掉S态所有中断（注意U态所有中断被自动屏蔽，而M态所有中断不能被屏蔽且会抢占），这等于是整个内核态均关闭中断。目前期望的一种做法是仅在trap类型为系统调用的时候打开S态中断开关，而trap类型为中断的话不打开中断开关，这样的话便不会产生中断嵌套。为了尽可能不丢失中断，中断处理的过程以及关中断spinlock的临界区需要尽可能短。
>
> 如果在内核态执行的时候触发S态中断，此时我们需要新增一套trap上下文保存与恢复代码，将trap上下文原地保存在内核栈上，如果是时钟中断的话，似乎也可以自然的进行任务切换。好像也就不用一些其他的东西了。目前完全没有必要进行中断嵌套了。
>
> ---
>
> 那么xv6是如何处理的呢？与我所想的差不多，时钟中断仅在hart0上处理，且仅在U态trap到S态类型为syscall的时候会重新打开中断。如果是从S Trap到S，仅有系统调用嵌套S态中断一种可能，此时如果sstatus.sie=1会panic。

---

接下来，需要研究进行的是内核态同步互斥（基于内核线程）还是用户态同步互斥（基于进程），它们分别需要调用怎样的接口或者是哪些系统调用。

---

09/10/21 慕课review

关于临界区的要求（这个原先我总是感觉有些混乱，现在看起来的话比较清晰了，但是这些概念的使用似乎有些复杂）

* 空闲则入：如果当前没有进程处于临界区，则任何进程可以进入临界区

* 忙则等待：如果当前已经有进程处于临界区，则任何其他进程暂时不能进入临界区

  （上面这两个概念其实可以概括为：同一时间最多有一个进程能处于临界区，也就是临界区的约束条件。如果当前没有进程在临界区的话，显然可以进入）

* 有限等待：这里应该指的是不能出现饥饿现象

* 让权等待：也就是阻塞

所以，如果从临界区的定义、避免饥饿现象和通过阻塞提高CPU使用效率三个角度出发，就会更加清晰一点了。

为了实现互斥可以采用三种不同的方法：

1. 关中断

   这里的前提其实有点诡异，在不引入用户态中断的前提下，用户态是无权关闭内核态中断的！也就是这里的前提就是并发基于多个内核线程来展开。

   如果是从内核线程的角度来看，那么每个内核线程自然是在访问内核里面的数据结构，此时出现内核态中断的话也有可能访问到内核数据结构，这样就带来了潜在的并发冲突。

   关中断在多核环境下无效。而且还会有丢失中断的风险。

   在我们的实现中，为了简化代码，在内核态全程关中断。这并不意味着内核里面上了一把大锁，在多核环境下其他核其实是可以进来的，但那个时候我们需要将UPSafeCell换成Mutex

2. 软件同步方法

   第一种做法是开头`while (turn!=i)`，结尾`turn=j`。应该不受到中断影响。但它只能做到两进程交替进入，也就是说不能有某个进程连续两次进入临界区。因此不满足空闲则入。

   第二种做法设`flag[i]`表示`i`处于临界区（后贴标签）。开头`while(flag[j]==1); flag[i]=1`，结尾`flag[i]=0`。问题就是如果在`while`循环之后被切换出去，两进程可能同时被设置并进入临界区（注意是在临界区但不一定在运行），因此不满足忙则等待。所以如果可以关中断的话是能解决这个问题的。但是软件同步假设的是没有任何硬件支持，因此我觉得后面一些成功的方法**也可以用在用户态**。

   第三种做法设`flag[i]`表示`i`想进入临界区（先贴标签）。开头`flag[i]=1; while(flag[j]==1);`，结尾`flag[i]=0`。问题是如果在中间被切换出去的话不满足空闲则入。

   一种靠谱的方法是Patterson算法。`flag[i]`同样表示`i`想进入临界区，但同时有共享变量`turn`控制谁实际能进入临界区。实际上，开头`flag[i]=1; turn=j; while(flag[j]&&turn==j);`，结尾`flag[i]=0`。这样如果同时有多个进程想进入临界区的话，最后一个设置`turn`变量的进程反而会陷入等待。由于这个是设置`turn`为另一个进程的id，它仅支持两个进程间的同步。根据Wikipedia上的介绍，Patterson算法是满足互斥和有限等待的。

   Filter算法可以将Patterson算法拓展到进程数$N>2$的情形（貌似需要原子变量支持，但是有原子变量支持的话就根本用不到软件同步算法了）。只不过这里先不展开了。

   按照课上的讲法是另一个双进程的同步方法是Dekkers算法，然后它可以方便的拓展到多进程的版本，也就是Eisenberg&McGuire算法。

   感觉上还是有点复杂的。

   总体上评价一下这些软件同步方法吧。在证明它们的正确性的时候，仅仅在机器码级别（我想应该是这样的，如果源代码级别的话也太粗糙了）证明对于所有可能的交错顺序（个人比较满意这个翻译）都能满足互斥或是一些更多的要求。在中断的作用下才会进行进程交错，因此可以说中断是考虑到的。但是对于现代CPU而言早就有了更多需要讨论进来的特性。首先需要考虑到的是在编译器和硬件级别的乱序执行。这会使得我们写的代码并不会如我们期望一般执行，尤其是这种共享内存的敏感区域，可能需要加入一些软件屏障。其次就是多核需要考虑内存一致性模型。现在为了提高性能，多核对于内存的观察往往是不一致的，因此需要手动添加内存顺序来让硬件在合适的时候进行同步，这样在满足同步需求的情况下尽可能提高性能。这些软件同步方法由于时代限制只考虑单核或者可以理解为当代的顺序一致性模型，因此需要一些修改才能将这些古老的算法放到现代CPU上使用。但是既然已经不可避免要考虑到硬件特性，这就已经不是软件同步方法的初衷，同时这些硬件同步原语有着相比这些软件同步方法明显更加简单且有效的使用方法。因此可以说，至少在多核的现代CPU上，这些软件同步方法没有什么用武之地了。

   对了，还有一个问题就是软件同步方法要用到忙等。

3. 高级抽象方法

   基于关中断、原子指令来实现互斥锁。比如test-and-set指令。可以忙等也可以使用阻塞，像之前那种暂时yield也是可以的。

   在单核上，原子指令主要的作用是体现在不可分割，因此中断不能打断，也就解决了一些潜在的不一致问题。

   但是在多核上，除了不可分割特性之外，内存顺序也在起作用。这是为了将共享变量的内容在多个核上的高速缓存之间进行同步。

后面是一些其他的同步原语，包括信号量和管程，后面我们可能还要提供条件变量。信号量和锁是同一个级别的？？？后面又提到信号量是OS提供给用户进程的（也就是由OS来统一管理和协调），而软件同步方法是进程之间自己协调的一种类似协议一样的东西，姑且算有点道理吧。信号量的奇妙P/V操作。这里信号量是直接基于阻塞机制来实现的。如何理解信号量的P/V操作的原子性是由操作系统保证的？应该是说如果它们在用户态实现的话就会被中断打断，但是如果在内核态实现的话，实际上也是需要关中断的...?这里似乎也是有点小问题。

为什么二进制信号量和资源信号量等价？（这个忽然让我想起go语言里面的chan，缓冲区大小会影响通信是同步还是异步）不过看起来没有什么讨论的意义。资源初始值为1的信号量当成互斥锁来用，用来实现互斥。使用方法就是在临界区前后加上P/V对。资源初始值为0的信号量可以实现条件同步。假设两个进程分别有操作A，B，且A需要在B完成之后才能进行，则需要在B后面加上V操作，同时在A前面加上P操作（这个就类似于缓冲区大小为0的chan，唯一的用途就是用来同步）。

比如用来解决mpsc（也就是多生产者单消费者）问题。可以分解为互斥访问和两个条件同步。这个妙啊，看来之前根本没学会QAQ。

用信号量解决哲学家就餐问题，本质上其实是在用互斥锁。只要获取资源的先后顺序不形成回路即可。

读者写者问题如果采取读者优先策略的话，可以有一个资源数为1的信号量控制读写限制。由于同时可以存在多个读者，我们可以再设置一个共享变量表示当前读者的数量并用一个资源数为1的信号量保护它的访问。读者进入临界区之前，增加读者的数量，如果此时读者数量为1才对读写限制信号量进行P操作。读者退出临界区之后，减少读者的数量，如果此时读者数量为0才对读写限制信号量进行V操作。事实上还存在写者优先策略和读写公平策略。

接下来看Monitor（管程），这是为了解决同一个信号量的P/V操作分散在两个不同进程的麻烦，也是一种同步编程方法。条件变量是管程内部的一种同步机制。管程要求同一时间只能有一个线程在执行管程代码，但相比互斥锁，在执行管程代码发现当前无法继续执行下去的时候可以暂停，等到可以继续执行的时候再继续。管程还属于一种面向对象编程方法。管程包括一个互斥锁（用来控制同一时间只有一个线程在执行管程代码）和多个条件变量（其实可以简单的理解为多个等待队列）。

其中的精髓是条件变量的`wait`操作将管程的互斥锁作为参数接受进来，它是在管程内部也就是持有该互斥锁的情况下调用`wait`的，而在`wait`里面，它在切换到其他线程之前（这里可以看出管程需要维护一个就绪队列，此时它需要切换到某一个就绪线程）需要交出互斥访问权，也就是释放互斥锁，然后在切换回来之后（由于其他线程调用了`signal`操作）再获取互斥锁回到管程内部。

比如之前的mpsc问题就可以用管程来实现。总共只需要一个结构体，实现读写两种操作。每个线程只需调用这两个接口函数即可。在两个接口函数的开头和结尾分别获取和释放管程内部的互斥锁。但是有趣的是如果在接口函数内部调用条件变量的`wait`操作的话，互斥锁会被暂时释放并切换到其他就绪线程。这里的就绪线程可能是从某个条件变量的等待队列中刚刚被唤醒的线程，也有可能是刚刚进入等待管程互斥锁的线程。所以一种可行的实现方法是：唤醒一个线程的时候直接加入到互斥锁的等待队列就行了。

管程条件变量的释放方式：Hansen做法，执行唤醒操作的线程更优先，也即调用`signal`之后继续执行直到主动交出互斥访问权，连续执行效率更高，更为广泛使用；Hoare做法，被唤醒的线程更优先，也即执行唤醒操作的线程调用`signal`之后立即交出互斥访问权，但是不一定立即就能开始执行被唤醒的线程，这种做法响应延迟应该较低。（不过我不觉得单凭while循环还是if就能体现二者之间的差异）

