memory order不仅关系到reorder的限制，还需要涉及共享数据结构（多个内存位置）的多核通信。可以这样想，acquire到某个锁变量的核必然需要从刚刚release该变量的核的缓存中同步共享数据结构。不然，出于通信延迟的影响，仅靠缓存一致性协议并不一定能够保证整个共享数据结构均一致。

常见的原子指令有compare-and-swap/fetch-and-increase/test-and-set等等，又比如RV中的Atomic Memory Operation，但是它们不好的地方在于同时操作中包括读写两部分，这给微体系结构设计带来了麻烦。因此RV中有另一种指令对LR/SC，LR会在当前hart的寄存器上预留一个地址，如果发生了上下文切换或者中断则该预留失效，如果其他hart写入了包含该地址的cache line使得cache line的状态发生变化则也失效。SC就会看是否失效，如果没有失效的话才会正式写入。

如果使用AMO的话，也并不用每次都直接CAS，这样的开销比较大。在支持缓存一致性的系统上，比如锁变量的值为0代表没有被占用，则线程可以先循环读变量等待变量的值变为0，这里不会用到CAS仅仅是正常的读入，之后所有进入该区域的hart再通过CAS来抢锁，总线会将它们的请求串行化，只有第一个能够看到0，其他的看到的都是1，随后再返回开头等待锁变量变为0。

注意，上述讨论仅需要缓存一致性模型，因为从头到尾仅涉及锁变量本身。但很多情况下锁变量是用来保护更大的数据结构的，仅有锁变量本身是不够的，这就需要引入多内存位置的内存一致性模型了。

缓存一致性模型仅能够做到单变量访问的一致性，但是其时序性得不到保证。它只能保证另一个核终将看到一个核最新写入的值，但是并不能够约束在什么时间点之前必须看到，众所周知，这会受到很多随机因素的影响，比如通信延迟、调度顺序、数据传输延迟等等。这在共享包含多个变量的数据结构的同步问题中会引发不一致问题。这里所谓的不一致指的是其执行结果无法对应到任何一个全局顺序。书中给出了一个典型例子，它就涉及双标志位：线程1的操作是：A=0;A=1;if B==0...；线程2的操作是：B=0;B=1;if A==0...；如果按照程序员期望看到的程序顺序，两个线程无论以何种方式交错也不会出现两个条件判断同时为真的情况。但在各种调度、延迟的影响下就有可能会出现这种情况。书中给出的解释是write invalidate可能被延迟，同时处理器被允许在延迟期间继续执行，那么双方就有可能在互相收不到对方修改了关键变量的消息的情况下往下走，导致双双满足条件。

为了解决这个问题我们需要通过内存一致性模型（又称内存顺序）限制一个值在什么时间之前必须被某个核看到。最符合直觉也是最简单的是顺序一致性模型(sc)，也就是每个核上均按照程序顺序，同时对于所有可能的执行结果（其实这个也挺难定义的）均存在一个全局顺序，可以看成各个核上的顺序交错而成（事实上刚刚我们已经在这样思考问题了），该全局顺序应与执行结果一致（即，读到总是最新写入的结果）。但是这样无法得到较高的性能，比如写入一个值之后，必须等待所有的invalidation全部完成之后才能向下走。因此，这种模型仅出现在较古老的机器上面。

事实上，大多数情况下我们并不需要如此严格的内存顺序。因为仅在访问一些线程间共享的数据结构时才需要严格进行串行，这里的串行意味着任意两段完整的对共享数据结构的操作都从时间上不相交，且被一对同步操作隔开（比如最经典的lock-unlock）。否则，由于各种速度的不同，将会出现无法预测也不被我们所期望的行为，即数据竞争。目前的大多数有实际意义的程序均满足这种同步属性，对于这种限制较少的需求，CPU设计者只需实现一个更加松散的一致性模型，由系统程序员封装到库中使得普通程序员可以方便的使用这些同步原语。在这些同步原语的加持下，同步程序在松散一致硬件上的运行结果可以和在顺序一致硬件上的运行结果相同。

下面就介绍几种松散一致性模型。在此之前，需要先明确一点，在内存顺序上，读是比写要更关键的。大概可以理解为读的结果会对后续指令的执行产生影响，而大多数情况下写入就不会有这种效果。目前我并没有系统性学习过乱序执行，但是猜想一下，内存相关操作是允许乱序执行但一定顺序提交的。当然这种乱序是受到限制的，有一些数据、控制依赖关系需要被满足。在此基础上，能够想象到的一种场景是：某个操作cache miss了，我们可以先进行后面的操作，这在单核上不违背依赖关系的时候也许没有问题，但在多核环境下，这种动态调度显然会影响原有的语义。（这里提一下，量化研究方法的原文比较微妙，暂时不知如何转换为中文：X->Y means that operation X must complete before operation Y is done，这里的complete/done应该是ILP里面的术语，等到之后再深入研究）为什么会有影响呢？因为一旦涉及到多个内存位置之间的同步关系，时序就非常重要了，尤其是实际发起（仅仅是多个阶段中的某一个阶段）内存操作的顺序也就很重要了。

顺序一致性模型Sequential Consistency必须维持R->R,R->W,W->R,W->W也就是不允许任何乱序。Total Store Ordering, TSO又称Processor Consistency允许违反W->R，因为R对于同步来说是更关键的，提前去读似乎也没那么难以理解。更进一步，Partial Store Ordering在TSO的基础上允许违背W->W。Weak Ordering和Release Consistency都允许违背所有偏序。设操作S为一个同步屏障，只有Release Consistency将同步屏障拆为两种，分别是acquire语义的sA以及release语义的sR。其他一致性模型的屏障可以理解为同时具有acquire和release语义。S屏障比较强（在RV里面应该是fence指令），内存操作的乱序不允许跨越该屏障，而且在同步方面，屏障后面的所有操作必须能够看到屏障之前的所有操作。在屏障之前和之后，则可以根据内存一致性模型的严格性要求进行乱序。相对来说，acquire语义要求屏障后面的操作不能被乱序到屏障之前（sA->R,sA->W），而release语义要求屏障前面的操作不能被乱序到屏障之后（R->sR,W->sR），两类屏障是顺序一致的（sA->sA,sA->sR,sR->sA,sR->sR）。同时，很容易被人们忽略的一点是跨屏障的共享数据结构必须同步，由于之前我们有偏序 OpList1->sR->sA->OpList2，在这个序列中由于中间存在屏障，OpList2必须能够看到OpList1中的所有操作。这就是说新拿到锁的核必须能够立即看到最新的共享数据结构。因此，我们之前又忽略的一点是在屏障前后内存是否被同步了，从而认为屏障仅仅起到阻止乱序的功能，实际上数据同步在多层缓存结构中显得尤为关键。

之后可以通过举一些乱序超标量的例子来说明顺序如何被打乱了。