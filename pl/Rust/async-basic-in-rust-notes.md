[原文](https://cfsamson.github.io/book-exploring-async-basics/1_concurrent_vs_parallel.html)

## 1. 并发与并行

* 并发是指宏观角度上，在一段时间内我们要完成多个任务，因此我们要合理的调配 CPU 和内存资源给每个任务；而并行可以理解成并发分配资源的一种特殊情况，在 CPU 和任务类型合适的情况下，在同一时间，我们可以让多个任务都在执行。

* 由此可见并行不一定要做到并发，这是对任务类型和资源情况有要求的。而如果多个任务并行执行，在这段时间一定是一个并发系统。

* 如果多个任务并发而不并行，它们就必须有能够暂停并保存进度的能力，被我们称为**可中断的**（interruptable）。

* 作者提到，最早使他认识到并行和并发区别的是资源的利用效率。并行只是给一个任务分配了更多的资源，因此与资源利用效率无关；而由于并发无论如何不能使单个任务跑的更快，那么如果能合理利用资源的话，却能使多个任务完成的总体所需时间缩短，所以并发非常关注资源的利用效率。

  个人认为，并行也是要讲究资源利用效率的，比如常见的可拓展性指标。在现在的高并发场景下，其实多核、内存、磁盘等资源都是要物尽其用，才能够达到高吞吐量。此时尽管多个核都在跑，一定是一个并行场景，但我们很少讨论并行。而当我们提到并行的时候，往往是大规模并行计算，也就是从头到尾只有一个任务，我们要对它进行优化，尽可能减小它的运行时长。其实，可拓展性无论是高并发场景还是大规模并行计算场景应该都是一个可靠的评价指标。

* 作者举了一个用咖啡机制作咖啡的例子。其中最重要的是，我们要尽可能**消除等待和没有意义的工作**。这在编程中分别对应**阻塞**（blocking）和**忙等待循环**（busy loop polling）。

  如果有两个人一起做咖啡，即使用比较低效的方式，总时间也能够比得上单人情况下比较优的方案。但是这样的资源利用效率仍然比较低。正如经典的防止 UI 卡死的方式，我们自然可以在主线程之外重新开一个线程在里面 block 或者 busy loop poll，不会影响到主 UI 线程。这样也绝不是最优的，因为它也在某种程度上浪费了 CPU 资源，甚至可能浪费掉整整一个核。

  在比较聪明的做法里面，我们在准备糖和牛奶的时候咖啡机也在工作，那么这是不是一个并行呢？事实上，我们需要写的代码只控制我们自己的行动。你可以将启动咖啡机类比成一次数据库查询，在等待数据库结果的时候，我们就可以做其他事情了；而数据库是在其他服务器上运行的代码，我们并不需要关心。所以，这并不是一个并行。

* 所以，并行意味着堆积更多资源让一个任务跑的更快；而并发着力于聪明的调度资源（大多数情况下使用异步是一个不错的解决方案），消除无谓的等待和无意义的工作，提高资源利用率，让多个任务的总体完成时间更短。这意味着，对于单个任务并发是不起作用的，而是应该想办法将其分成若干独立的执行流用多核去解决，这也就是并行。

* 并发的两种主要应用场景：其一就是在某个任务等待 I/O 的时候，我们要将它休眠，并切换到其他的任务合理利用 CPU 资源；其二常常和 GUI 有关。为了让 UI 高响应，假设在单核的情况，我们需要每隔 16ms 就将当前所执行的后台任务暂停，更新一次 UI，然后再恢复并继续执行原来的后台任务。这样的话，GUI 的刷新频率达到 60Hz，使用体验将非常流畅。（因此，我们需要在主循环里维护一个事件队列）

* 关于 OS 线程，作者说：OS 线程即可以用来编写并行程序，也可以用于达成并发（我头脑中想象到的就是服务器每接受到一个请求就开一个新线程进行处理，同步互斥开销和上下文切换开销不可恭维。）

* 作者最后提到我们应当站在 OS 的角度看待我们编写的程序。在 OS 看来，它只是一个普通的进程，当时间片耗尽它就会被切换为其他进程（进程上下文切换），如果遇到了中断，CPU 会先去处理中断（中断上下文切换），这都要求暂停并恢复的能力。所以，在 OS 看来这是一个天然的并发场景。但如果我们只着眼于自己编写的程序的话，我们会认为它就是会从头不停地执行到尾。

## 2. OS 与 CPU 发展史

* 最早的计算机只有单核，操作系统没有线程、调度、多任务的概念。操作系统只是完全将 CPU 使用权交给一个程序，如果程序员乐意的话，他可以自己在程序中实现多任务。但是当使用鼠标的窗口化交互式 UI 成为常规的时候，这个简单的模型完全不能工作了。

* 非抢占式多任务曾被用来保持 UI 的响应。在这种模型下，程序员需要负责让操作系统执行其他任务，比如响应鼠标的输入或是执行一个后台任务。程序员需要通过 `yield` 将 CPU 的使用权交还给操作系统来达到这一目的。但是由于这将过大的责任托付给程序员，常常会导致很多错误。程序中的一个小错误就有可能会导致整个操作系统的崩溃，这使得整个操作系统的用户体验很差。

* 解决方案是将分配 CPU 资源给各个任务（包括 OS 自身）的使命交给 OS。OS 可以暂停一个任务，做一些其他事情，并切换回来继续执行之前的任务。因此 OS 还需要通过任务上下文切换来进行任务调度。这个过程每秒钟会发生很多次，不仅可以保持 UI 的响应，还能有时间执行一些后台任务或者处理 I/O 事件。目前，这种抢占式多任务设计被 OS 广泛采用。

* 随着 CPU 不断进化，它的功能越发复杂，比如它内置多个 ALU 以及更多的逻辑单元。CPU 的生产商认识到 CPU 的性能并没有完全利用。比如，当一个操作只需要 CPU 中部分模块的时候，一条指令可以同时在 ALU 中执行。这即是超线程的开端。

  现在我们的 PC 有 6 个核和 12 个逻辑核，这就是超线程技术的体现。当一个核在运行线程 1 上的代码的时候，它可以同时利用 CPU 未利用的部分运行线程 2，以此做到用一个物理核来模拟两个逻辑核。当然，这需要很多小技巧。

  基于超线程技术，即使我们只有一个核，我们也可以在第一个逻辑线程中更新 UI，同时在第二个逻辑线程中做事件响应。这是对硬件更充分的利用。

* 众所周知，处理器的时钟频率已经很长一段时间陷入瓶颈。处理器曾经通过优化缓存、分支预测、超标量执行、和流水线设计来提升性能，但是这样的做法收效越来越低了。于是，现在通常在一块芯片上放置多个核，通常这些核还支持超线程。

## 3. OS 与 CPU

* 有一句话这样说到：“自从 90 年代开始，操作系统就在创造一种程序同步执行的假象。”只有作为程序员才可以这样认为。站在 OS 和 CPU 的视角，根本就不存在同步。OS 一般采用抢占式调度，更高优先级的任务会抢占当前低优先级的任务。即使不考虑优先级，当时间片耗尽或者收到了中断的时候，也都需要暂停任务，保存上下文并等待之后切换回来。这是典型的并发场景。在多核的情况下，虽然某个任务有可能不经历任何暂停从一而终，但是由于没有任何东西能够保证这一点，它仍需要注意到自身是随时可能被暂停的。现代 CPU 设计更是远远比每个周期执行一条指令这简单的模型要复杂。多级流水线、超标量执行、乱序执行都和一条一条指令向下执行的理想同步相去甚远。
* 当我们编写程序进行 I/O 的时候，往往不是直接和硬件打交道，而是要通过操作系统提供的系统调用。因此，如果想写出高性能的程序，我们就必须了解操作系统如何与硬件打交道，这样才能更加合理的利用操作系统提供给我们的服务。

### 3.1 与 OS 交互

