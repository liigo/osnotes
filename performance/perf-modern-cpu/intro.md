[book link](https://book.easyperf.net/perf_book)

## 为什么我们仍需性能优化

软件开发者基于层数过多的抽象进行编程提高开发效率，然而可能没有充分利用硬件的性能（原文中提到对硬件的亲和性不足）。在摩尔定律未失效之前，硬件性能高速提升，因此很多软件开发商会等到最新的硬件上市之后再开发软件，从而节约移植所需的人力资源。但是，在单核性能增速已经放缓的现在，就需要从软件的层面来优化代码而不能仅仅依赖硬件的性能，这样才能尽可能提升软件性能。

即使很容易就能买到超过100逻辑核的服务器CPU，也需要关注性能优化。因为大多数情况下，性能并不能随核数而线性提升（数据竞争、带宽限制...）。实际上发现性能瓶颈并找出解决方案对于一个项目而言是至关重要的。

据调查/研究所示，从软件层面进行优化仍有巨大的潜力（如通过更换编程语言以及利用相关CPU特性可以将4096阶矩阵乘法加速60,000倍以上），但是这需要付出巨大的努力进行针对性优化，默认的软件栈是无法做到这一点的。

如果软件无法获得理想性能，常常是因为以下这些重要的因素：

1. CPU局限性。虽然目前CPU已经能以极快的速度执行指令，但是它对于指令的优化还没有智能到把冒泡排序的代码自动转换为快速排序的程度。当然，硬件是不可能解决所有问题的。
2. 编译器局限性。编译器现在很擅长消除冗余操作，但是在函数内联和循环展开方面尚有不足。也许编译器无法生成最优的代码。比如编译器是否应该将函数内联在它被调用的位置这个问题就没有简单的是或否的答案，编译器事实上需要考虑多个不同因素。编译器常常基于复杂的费用模型或启发式算法，然而它们并不适用与每一个场景。同时，编译器只有在确定优化不影响程序语义且安全的情况下才会去做，对于所有可能的场景确认这这一点极其困难，因此编译器的优化通常趋向于保守。最后，编译器也不会对程序中的数据结构进行变化，即使这对最终的性能有着关键性的影响。
3. 算法复杂度分析局限性。程序员通常会选取理论复杂度最优的算法来解决问题，但在某些场景下它们并不是最高效的。比如快速排序复杂度优于冒泡排序，然而在N非常小的时候，冒泡排序的表现实际上更好。程序员往往忽略算法复杂度中的常数（包括分支预测和缓存的巨大影响），自然无法获得更高的性能。

上面可以看出从软件上进行性能优化有巨大的进步空间。尽管软件栈有很多层，但最底层（如BIOS/bootloader/OS）很难被我们掌控（如果我们是写内核的那又不同了），因此这里主要关注源代码编写和编译器优化（事实上通过生成更优的代码，它能带来很有吸引力的性能提升）。作者的个人经验：90%的源代码变换无需触及编译器源码，仅需大体上理解编译器的机制即可。

当然，在单核性能提升接近瓶颈的今天，我们还需要关注如何高效进行多线程间通信、减少不必要的资源消耗以及其他多线程程序中的典型问题。

除了优化软件之外，还可以通过设计新算法和流水化硬件来提升性能。开发者基本上都是基于已有的硬件进行开发而不太可能推动硬件设计的进步，然而理解现代CPU设计对于应用性能优化来讲仍然是十分重要的。

这本书中提到的方法致力于榨干应用的最后一点性能。一些优化方式并不显著，可能仅能带来10%的性能提升。然而不要低估它的重要性，因为在大规模分布式场景下，这就能够节约大量的成本，尤其是功耗的降低。

## 哪些领域需要性能优化

如高性能计算、云服务、高频交易、游戏开发或其他性能敏感的领域。比如搜索引擎，更高的性能能够吸引更多用户。有趣的是，除此之外，今天很多通用的应用或服务也要求高性能。很多我们日常使用的工具如果不满足它们的性能需求甚至不会存在。比如IDE中的自动补全功能要求高响应并提供用户连贯的编码体验。

今天很多高速的工具并未被用在它们设计中的目标领域中。比如，类似Unreal和Unity的游戏引擎曾经被用在建筑、3d模拟、影片制作和其他领域中。因为它们有很高的性能，它们对于需要2d/3d渲染、物理引擎、碰撞检测、音效和动画的应用而言是一个自然的选择。

当然，性能仅仅是产品竞争力的来源之一。

性能工程极为重要且值得，然而需要消耗大量时间。实际上，性能优化是永无止境的。然而遇到瓶颈——即继续优化会带来极高的工程开销且不太值得是不可避免的。从这个角度来看，知道何时停止优化是很关键的。一些组织通过在代码上注明开销来按需达成这一点。

在开始优化之前确保你有着充足的理由，而不是为了优化而优化。谨慎的性能工程总是从被清晰定义的性能指标开始，它们通常说明你要达成的目标以及需要实现它们的原因。
